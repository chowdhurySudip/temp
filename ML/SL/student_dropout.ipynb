{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16e4bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter_ns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f7952f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/predict+students+dropout+and+academic+success/data.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ee8bf83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df.Target.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40044fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Target = df.Target.apply(lambda x: classes.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "200fa7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Target\", axis=1)\n",
    "y = df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6882c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X.columns] = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2815f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d3adb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(perf, time):\n",
    "    result = {\n",
    "        \"precision\": perf[\"macro avg\"][\"precision\"],\n",
    "        \"recall\": perf[\"macro avg\"][\"recall\"],\n",
    "        \"f1-score\": perf[\"macro avg\"][\"f1-score\"],\n",
    "        \"accuracy\": perf[\"accuracy\"],\n",
    "        \"time (ms)\": time\n",
    "    }\n",
    "    return pd.DataFrame([result])\n",
    "\n",
    "def train_and_evaluate(estimator, X_train, y_train, X_test, y_test):\n",
    "    train_start = perf_counter_ns()\n",
    "    estimator.fit(X_train, y_train)\n",
    "    train_end = perf_counter_ns()\n",
    "    train_time = int((train_end - train_start)/1000000)\n",
    "    \n",
    "    test_start = perf_counter_ns()\n",
    "    y_test_pred = estimator.predict(X_test)\n",
    "    test_end = perf_counter_ns()\n",
    "    test_time = int((test_end - test_start)/1000000)\n",
    "    \n",
    "    y_train_pred = estimator.predict(X_train)\n",
    "    train_perf = classification_report(y_train, y_train_pred, target_names=classes, output_dict=True)\n",
    "    test_perf = classification_report(y_test, y_test_pred, target_names=classes, output_dict=True)\n",
    "    report = {\n",
    "        \"test\": get_metrics(test_perf, test_time),\n",
    "        \"train\": get_metrics(train_perf, train_time),\n",
    "    }\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6593087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_performance(results):\n",
    "    mean = results.mean(axis=0).values\n",
    "    return pd.DataFrame([mean], columns=results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6b627959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_single_model(X, y, Clf, estimator_params):\n",
    "    train_results, test_results = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=SEED)\n",
    "    for train_idx, test_idx in split.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        estimator = Clf(**estimator_params, random_state=SEED)\n",
    "        report = train_and_evaluate(estimator, X_train, y_train, X_test, y_test)\n",
    "        train_results = pd.concat([train_results, report[\"train\"]], ignore_index=True)\n",
    "        test_results = pd.concat([test_results, report[\"test\"]], ignore_index=True)\n",
    "    return train_results, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "288b6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clf = DecisionTreeClassifier\n",
    "clf_params = {}\n",
    "train_res, test_res = train_single_model(X, y, Clf, clf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aae5ef65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617784</td>\n",
       "      <td>0.619724</td>\n",
       "      <td>0.618372</td>\n",
       "      <td>0.679443</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score  accuracy  time (ms)\n",
       "0   0.617784  0.619724  0.618372  0.679443        1.2"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_performance(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10d8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
